# üêá Advanced Message Queuing Protocol (Rabbit MQ)
O intuito desse reposit√≥rio √© testar e aprender a usar o sistema de mensageria que o RabbitMQ proporciona, durante todo o desenvolvimento vou explicando o conceito de cada etapa que a propria documenta√ß√£o do Rabbit proporciona para melhor aprendizado.

Cada etapa (exceto a primeira) ser√° separada por Pull Requests para que possa ser mais f√°cil de identificar as etapas da vers√£o final.

## ([#0](https://github.com/lucasgianine/message-queuing/commit/c86a7cd0750668b64d3e57371d61874107304e26)) Hello world!
O conceito dessa etapa √© apresentar o b√°sico da mensageria, teremos um <i>Producer</i> que ir√° enviar uma mensagem, a <i>queue</i>, ou <i>fila</i> que ir√° fazer o processo onde armazenar√° a mensagem em um buffer para que, finalmente, seja entregue ao <i>Consumer</i>, que imprimir√° a mensagem.

```mermaid
flowchart LR
  P["Producer"]
  Queue["Hello world!"]
  C["Consumer"]

  P --> Queue --> C
```

Utilize esses comandos para teste:
```bash
  # shell 1
  npm run consumer

  # -> [*] Waiting for messages. To exit press CTRL+C
  # -> [x] Received Hello World!
```

```bash
  # shell 2
  npm run producer

  # -> [x] Sent: Hello World!
```

## ([#1](https://github.com/lucasgianine/message-queuing/pull/1)) Work Queues
Vamos trabalhar em criar Work Queues (ou Task Queues) para distribuir tarefas demoradas entre v√°rios workers, ou seja, quando uma tarefa exije muitos recursos, todo fluxo espera que ela seja conclu√≠da para que a mensagem seja exibida, a ideia do Work Queues √© que agendemos a tarefa para que ela seja feita mais tarde.

```mermaid
flowchart LR
  P["Producer"]
  Queue["Task"]
  C1["Consumer 1"]
  C2["Consumer 2"]

  P --> Queue --> C1
  Queue --> C2
```

Utilize esses comandos para teste:
```bash
  # shell 1
  npm run consumer

  # -> [*] Waiting for messages. To exit press CTRL+C
  # -> [x] Received <mesagem>!
  # -> [x] Done
```

```bash
  # shell 2
  npm run producer <mensagem>

  # -> [x] Sent: <mensagem>
```

#### Round-robin dispatching
Durante esse teste, existe uma maneira de distribui√ß√£o que √© chamada de `round-robin`, que por padr√£o, cada mensagem ser√° enviada por sequencia, fazendo com que cada consumidor receba o mesmo n√∫mero de mensagens, a diferen√ßa √© que as mensagens ser√£o distribu√≠das em shell diferentes.
Se executarmos o `npm run consumer` em dois shell, e depois enviarmos as mensagems, podemos ver que cada um ter√° diferentes resultados, pois foram distribu√≠dos em seque√™ncia.

#### Message acknowledgment
√Ås vezes, fazer uma tarefa leva alguns segundos, e por sua vez, algumas tarefas acabam morrendo no meio do caminho sem ter chance de serem executadas, e tudo que estava sendo processado acaba sendo perdido no meio do caminho, e se fizessemos algo para que, assim que uma tarefa morrer, ela passasse seu trabalho (que estava em andamento) para o pr√≥ximo <i>producer</i>?
```typescript
  // worker.js
  noAck: false // acknowledgment mode
```
Aplicar noAck como `false` (que anteriormente era `true`) garante que, mesmo que voc√™ encerre um worker (com CTRL+C) nada ser√° perdido, todas as mensagens n√£o confirmadas ser√£o reenviadas (desde que esteja no mesmo canal em que ela foi enviada).

#### Message durability
Ainda que garantimos que mesmo que o <i>consumer</i> acabe, as mensagens ainda existam, n√£o garantimos que se o servidor RabbitMQ parar essas mesmas mensagens deixem de existir, pois quando o RabbitMQ para ele esquece todas as queues e mensagens, a n√£o ser que fa√ßamos ele lembrar.
Fazemos ele se lembrar das queues utilizando `durable`, e para as mensagens `persistent`
```typescript
  channel.assertQueue(queue, {
      durable: true
    })

  channel.sendToQueue(queue, Buffer.from(message), {
    persistent: true
  })
```

#### Fair dispatch
Esse m√©todo √© interessante por um motivo: Supondo que mensagens √≠mpares sejam pesadas e mensagens pares sejam leves, um trabalhador ficar√° constantemente ocupado e outro quase n√£o ter√° trabalho para fazer, o Rabbit faz com que as mensagens sejam enviadas uniformemente, sem se preocupar com isso, pois ele s√≥ despacha as mensagens que entram na queue/fila

```mermaid
flowchart LR
  P["Producer"]
  Queue["Task"]
  C1["Consumer 1"]
  C2["Consumer 2"]

  P --> Queue -- Prefetch=1 --> C1
  Queue -- Prefetch=1 --> C2
```

Pra corrigir esse feito, usamos `prefetch` com o valor `1` para que o Rabbit entenda n√£o dar√° mais de uma mensagem para um trabalhador por vez enquanto a mensagem n√£o for conclu√≠da at√© que um trabalhador esteja livre.
```typescript
  channel.prefetch(1)
```

## ([#2](https://github.com/lucasgianine/message-queuing/pull/2)) Publish/Subscribe
Dessa vez iremos entregar uma mensagem para v√°rios consumidores, criaremos um registro simples com dois programas, onde um emitir√° mensagens de registro e outro que vai receber e imprimir, no nosso programa, cada c√≥pia em execu√ß√£o do receptor receber√° as mensagens, onde o receptor poder√° se comunicar com os dois queues ao mesmo tempo.

Toda ideia do Rabbit √© que, na verdade o <i>producer</i> nunca envie mensagem diretamente para fila (pois na realidade √© que o <i>producer</i> nem sabe se a mensagem chegar√° at√© l√°), mas ao inv√©s disso ele envie mensagens para uma `exchange`, pois ela sabe exatamente o que fazer com a mensagem que recebeu para empurr√°-l√° para uma <i>queue</i>.

```mermaid
flowchart LR
  P["Producer"]
  X{"Exchange"}
  Q1["Queue 1"]
  Q2["Queue 2"]

  P --> X --> Q1
  X --> Q2
```

H√° alguns tipos de exchanges, mas vamos trabalhar em cima do `fanout`: Ela transmite todas as mensagens que recebe para todas as filas que ela tem conhecimento.
```typescript
  channel.assertExchange('logs', 'fanout', { durable: false })
```

#### Filas tempor√°rias
Dar o nome para uma fila √© importante para compartilharmos ela entre os <i>produces</i> e <i>consumers</i>, mas no caso dessa aplica√ß√£o de logs, n√£o precisamos criar uma fila permanente, deixaremos o nome da fila vazio para que o pr√≥prio servidor possa dar um nome aleat√≥rio, j√° que nesse momento isso n√£o √© priorit√°rio visto que a fila, depois de ser consumida, dever√° ser apagada automaticamente.
```typescript
  channel.assertQueue('', {
    exclusive: true
  })

  // Exemplo de retorno: amq.gen-JzTY20BRgKO-HjmUJj0wLg
```

Depois de todo o processo de criar <i>exchange</i> e as filas tempor√°rias agora vamos fazer nossa <i>exchange</i> enviar mensagem para a <i>fila</i>.
```mermaid
flowchart LR
  P["Producer"]
  X{"Exchange"}
  Q1["Queue 1"]
  Q2["Queue 2"]

  P --> X -- Binding --> Q1
  X -- Binding --> Q2
```

Chamamos de `binding` (traduzido: Vincula√ß√£o) o relacionamento entre exchange (troca) e uma queue (fila).
"Pode ser lido como: A queue est√° interessada em mensagens dessa exchange."
```typescript
  channel.bindQueue(queue_name, 'logs', '')
```

Utilize esses comandos para teste:
```bash
  # shell 1
  npm run receive_logs

  # -> Ser√° criado um arquivo .log na pasta src/logs
  # -> No arquivo aparecer√° a <mensagem> escrita no pr√≥ximo shell
```

```bash
  # shell 2
  npm run emit_logs <mensagem>

  # -> [x] Sent: <mensagem>
```

De forma simples: Criamos um sistema de registro simples que trasmite mensagens de registros (logs) para receptores.

## ([#3](https://github.com/lucasgianine/message-queuing/pull/3)) Routing
Trabalharemos com roteamento junto ao que foi aprendido no item anterior, redirecionaremos mensagens de erros cr√≠ticas para o arquivo de log (economizando espa√ßo no disco).
Ainda trabalharemos em cima das bindings, e dessa vez, passaremos par√¢metros de chave de binding para que possamos fazer uma <i>exchange</i> direta para diversas queues

Anteriormente envi√°vamos mensagens para todos os <i>consumers</i> sem nenhuma filtragem, isso se dava ao fato de usarmos a troca `fanout`, dessa vez usaremos a troca `direct` que enviar√° mensagens para queues espec√≠ficas, e todas as outras mensagens sem um binding key ser√£o descartadas.

```typescript
// logs/emit_logs.js
const exchange = 'direct_logs'
channel.assertExchange(exchange, 'direct', {
  durable: false
})
channel.publish(exchange, severity, Buffer.from(message))
```

```typescript
// logs/receive_logs.js
args.forEach((severity) => {
  channel.bindQueue(q.queue, exchange, severity)
})
```

Aplicaremos esse tipo de troca no nosso sistema de logs, trocaremos `fanout` por `direct` e forneceremos uma `routing key` na hora de publicar para selecionar a gravidade que o receptor ir√° receber.
`severity` √© o tipo de `routing key` que passaremos, nesse caso vamos assumir que ela seja `info`, `warning` ou `error`.

```mermaid
flowchart LR
  P["Producer"]
  X{"direct"}
  Q1["Queue 1"]
  Q2["Queue 2"]
  C1["Consumer 1"]
  C2["Consumer 2"]

  P --> X -- error --> Q1 --> C1
  X -- info --> Q2 --> C2
  X -- warning --> Q2
  X -- error --> Q2
```

Utilize esses comandos para teste:
```bash
  # shell 1
  npm run receive_logs

  # -> Ser√° criado um arquivo .log na pasta src/logs
  # -> No arquivo aparecer√° a <rountingKey> e a <mensagem> escrita no pr√≥ximo shell
```

```bash
  # shell 2
  npm run emit_logs <rountingKey> <mensagem>

  # -> [x] Sent '<rountingKey>': <mensagem>
```

## Refer√™ncia
- [RabbitMQ](https://www.rabbitmq.com/)
- [Documenta√ß√£o do RabbitMQ](https://www.rabbitmq.com/tutorials)
